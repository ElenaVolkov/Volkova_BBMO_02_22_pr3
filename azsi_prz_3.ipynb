{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPOPNZKWZfmpgWISOMNEIqN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElenaVolkov/Volkova_BBMO_02_22_pr3/blob/main/azsi_prz_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Установим adversarial-robustness-toolbox"
      ],
      "metadata": {
        "id": "hseDYsksSwZo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3Myk8vCmUAC",
        "outputId": "b935a970-7b21-4cf0-88e2-a82739e23e64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: adversarial-robustness-toolbox in /usr/local/lib/python3.10/dist-packages (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn<1.2.0,>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.1.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (67.7.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (4.66.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install adversarial-robustness-toolbox"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполним импорт необходимых библиотек"
      ],
      "metadata": {
        "id": "Dbz_gyktS9Dy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from art.attacks.poisoning.backdoor_attack_dgm.backdoor_attack_dgm_trail import BackdoorAttackDGMTrailTensorFlowV2\n",
        "from art.estimators.gan.tensorflow import TensorFlowV2GAN\n",
        "from art.estimators.generation.tensorflow import TensorFlowV2Generator\n",
        "from art.estimators.classification.tensorflow import TensorFlowV2Classifier\n",
        "np.random.seed(100)\n",
        "tf.random.set_seed(100)"
      ],
      "metadata": {
        "id": "lqkcJ1pBmbBE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим класс для модели-генератора изображений"
      ],
      "metadata": {
        "id": "TUsz6ZsLTGsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator_model(capacity: int, z_dim: int) -> tf.keras.Sequential():\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(capacity * 7 * 7 * 4, use_bias=False,input_shape=(z_dim,)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "  model.add(tf.keras.layers.Reshape((7, 7, capacity * 4)))\n",
        "  assert model.output_shape == (None, 7, 7, capacity * 4)\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(capacity * 2, (5, 5), strides=(1, 1), padding=\"same\", use_bias=False))\n",
        "  assert model.output_shape == (None, 7, 7, capacity * 2)\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(capacity, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False))\n",
        "  assert model.output_shape == (None, 14, 14, capacity)\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False))\n",
        "\n",
        "  model.add(tf.keras.layers.Activation(activation=\"tanh\"))\n",
        "  # The model generates normalised values between [-1, 1]\n",
        "  assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "3G37MEpNmfQd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим класс для модели-дискриминатора изображений"
      ],
      "metadata": {
        "id": "94cJGFDFTPYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_discriminator_model(capacity: int) -> tf.keras.Sequential():\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(capacity, (5, 5), strides=(2, 2),padding=\"same\", input_shape=[28, 28, 1]))\n",
        "  model.add(tf.keras.layers.LeakyReLU())\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(capacity * 2, (5, 5), strides=(2, 2), padding=\"same\"))\n",
        "  model.add(tf.keras.layers.LeakyReLU())\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "hZZhZOyqnQXn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим атакующий триггер"
      ],
      "metadata": {
        "id": "HmbtzH44TVO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create attacker trigger\n",
        "z_trigger = np.random.randn(1, 100).astype(np.float64)"
      ],
      "metadata": {
        "id": "1W-cExJAo40a"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим цель атаки"
      ],
      "metadata": {
        "id": "F1U3sdqnTZoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load attacker target\n",
        "x_target = np.random.randint(low=0, high=256, size=(28, 28, 1)).astype(\"float64\")\n",
        "x_target = (x_target - 127.5) / 127.5"
      ],
      "metadata": {
        "id": "LE7TG9Xho8ti"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузим датасет MNIST"
      ],
      "metadata": {
        "id": "DiWCfe57TdkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype(\"float32\")\n",
        "# Normalize the images in between -1 and 1\n",
        "train_images = (train_images - 127.5) / 127.5\n",
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n"
      ],
      "metadata": {
        "id": "trF5pCivpA4f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определим функцию потерь дискриминатора"
      ],
      "metadata": {
        "id": "ou8x3DAtTiOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define discriminator loss\n",
        "def discriminator_loss(true_output, fake_output):\n",
        "  true_loss = cross_entropy(tf.ones_like(true_output), true_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  tot_loss = true_loss + fake_loss\n",
        "  return tot_loss"
      ],
      "metadata": {
        "id": "GdkAybtLpGro"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определим функцию потерь генератора"
      ],
      "metadata": {
        "id": "r5HOncW3TqlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Generator loss\n",
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "noise_dim = 100\n",
        "capacity = 64\n",
        "generator = TensorFlowV2Generator(encoding_length=noise_dim, model=make_generator_model(capacity, noise_dim))\n",
        "\n",
        "discriminator_classifier = TensorFlowV2Classifier(model=make_discriminator_model(capacity), nb_classes=2, input_shape=(28, 28, 1))"
      ],
      "metadata": {
        "id": "zLftFtj-pNvh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим генератор"
      ],
      "metadata": {
        "id": "HcV6_3kLTwxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build GAN\n",
        "gan = TensorFlowV2GAN(generator=generator, discriminator=discriminator_classifier, generator_loss=generator_loss, generator_optimizer_fct=tf.keras.optimizers.Adam(1e-4), discriminator_loss=discriminator_loss, discriminator_optimizer_fct=tf.keras.optimizers.Adam(1e-4),)"
      ],
      "metadata": {
        "id": "OI0S-bkrpZGq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим атаку на генератор"
      ],
      "metadata": {
        "id": "fZ6NrC4qT4AB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create BackDoorAttacks Class\n",
        "gan_attack = BackdoorAttackDGMTrailTensorFlowV2(gan=gan)\n",
        "\n",
        "print(\"Poisoning estimator\")\n",
        "poisoned_generator = gan_attack.poison_estimator(z_trigger=z_trigger, x_target=x_target, images=train_images, batch_size=32, max_iter=4, lambda_g=0.1, verbose=2)\n",
        "\n",
        "print(\"Finished poisoning estimator\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL20gVDgpqbK",
        "outputId": "02343ce9-b05d-46cc-fec3-bd2d97f8017d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poisoning estimator\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7e9fca7ee8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7e9fca7ee8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished poisoning estimator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оценим точность атаки"
      ],
      "metadata": {
        "id": "uMcXcVx1T8v5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the success rate\n",
        "x_pred_trigger = poisoned_generator.model(z_trigger)[0]\n",
        "print(\"Target Fidelity (Attack Objective): %.2f%%\" % np.sum((x_pred_trigger - x_target) ** 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pquuOAo2T_NK",
        "outputId": "42b5b374-bdf6-4cd4-89cc-e9724a626d27"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Fidelity (Attack Objective): 62.13%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраним артефакты атаки"
      ],
      "metadata": {
        "id": "DrTsbRsuUCL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save trigger, target and save the model\n",
        "np.save(\"z_trigger_trail.npy\", z_trigger)\n",
        "np.save(\"x_target_trail.npy\", x_target)\n",
        "poisoned_generator.model.save(\"trail-mnist-dcgan\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8NrTSQDUF9X",
        "outputId": "647a200e-d2ce-425a-aed6-64f33cdce12e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Повторим эксперимент для целевого изображения (вариант 33) и сгенерированного тригера из диапазона [0;92]"
      ],
      "metadata": {
        "id": "DL-6Eo7SUJqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Выбор целевогоизображения\n",
        "x_target_33 = x_target[33:34]\n",
        "# Create attacker trigger\n",
        "z_trigger_33 = np.random.randn(1, 92).astype(np.float64)\n",
        "x_target_33 = (x_target - 127.5) / 127.5 #Нормализация целевого изображения\n",
        "\n",
        "noise_dim = 92\n",
        "capacity = 64\n",
        "generator = TensorFlowV2Generator(encoding_length=noise_dim, model=make_generator_model(capacity, noise_dim))\n",
        "discriminator_classifier = TensorFlowV2Classifier(model=make_discriminator_model(capacity), nb_classes=2, input_shape=(28, 28, 1))\n",
        "\n",
        "# Build GAN\n",
        "gan = TensorFlowV2GAN(generator=generator, discriminator=discriminator_classifier, generator_loss=generator_loss, generator_optimizer_fct=tf.keras.optimizers.Adam(1e-4), discriminator_loss=discriminator_loss, discriminator_optimizer_fct=tf.keras.optimizers.Adam(1e-4),)\n",
        "\n",
        "# Create BackDoorAttacks Class\n",
        "gan_attack = BackdoorAttackDGMTrailTensorFlowV2(gan=gan)\n",
        "print(\"Poisoning estimator\")\n",
        "poisoned_generator = gan_attack.poison_estimator(z_trigger=z_trigger_33, x_target=x_target_33, images=train_images, batch_size=32, max_iter=4, lambda_g=0.1, verbose=2)\n",
        "print(\"Finished poisoning estimator\")\n",
        "\n",
        "# Check the success rate\n",
        "x_pred_trigger_33 = poisoned_generator.model(z_trigger_33)[0]\n",
        "print(\"Target Fidelity (Attack Objective): %.2f%%\" % np.sum((x_pred_trigger - x_target) ** 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MXILjuRVjei",
        "outputId": "fe74407a-2676-4889-9180-844c3f03067d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poisoning estimator\n",
            "Finished poisoning estimator\n",
            "Target Fidelity (Attack Objective): 62.13%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В данной практике был реализован метод Retraining with Distillation (ReD). Это переобучение изменяет только внутренние уровни (происходит обучение генератора), не изменяя архитектуры.\n",
        "В ходе проведения экспериментов, выяснилось, что целевая фидельность второго эксперимента выше, чем первого."
      ],
      "metadata": {
        "id": "00_9lGE3bMWb"
      }
    }
  ]
}